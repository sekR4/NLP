{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d2f2c9",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "- Weights shared for each \"word cell\" (recurring)\n",
    "![image.png](img/rnn.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/TyJuk/recurrent-neural-networks)\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9299d",
   "metadata": {},
   "source": [
    "# Typical RNN Tasks\n",
    "- 1:n - e.g. give a word and get a sentence\n",
    "- n:1 - e.g. give a sentence and figure out if it's offensive or not (binary classification)\n",
    "- n:n - e.g. translate a sentence into another language\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca2c38",
   "metadata": {},
   "source": [
    "# Why?\n",
    "![image.png](img/rnn_q_matrix.png)\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db1fb2",
   "metadata": {},
   "source": [
    "# Simple RNN\n",
    "![image.png](img/simple_rnn.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/eaLt6/math-in-simple-rnns)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Formulas\n",
    "![image-2.png](img/rnn_math.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/eaLt6/math-in-simple-rnns)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"img/rnn_element_wise.png\" align=\"left\"/>\n",
    "\n",
    "This funny circle is standing for \"*a binary operation that takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices. It is to be distinguished from the more common matrix product.*\" [(Hadamard product)](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)) Also see: [How to do in Python](https://stackoverflow.com/questions/40034993/how-to-get-element-wise-matrix-multiplication-hadamard-product-in-numpy)\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b593a",
   "metadata": {},
   "source": [
    "# What are we training?\n",
    "![image.png](img/rnn_what_to_train.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/eaLt6/math-in-simple-rnns)\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022db7f",
   "metadata": {},
   "source": [
    "# Calculate Hidden State Activation `h` in Python\n",
    "*From h_t_prev to h_t*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9218bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06bb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hh = np.random.standard_normal((3,2))\n",
    "w_hx = np.random.standard_normal((3,3))\n",
    "h_t_prev = np.random.standard_normal((2,1))\n",
    "x_t = np.random.standard_normal((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab02b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hh\n",
      "\n",
      "[[ 0.12967326 -0.27805933]\n",
      " [-0.68666299  0.05393412]\n",
      " [ 0.40413422 -2.06988829]]\n",
      "\n",
      "w_hx\n",
      "\n",
      "[[-1.03164011 -0.8504492  -0.32841076]\n",
      " [-0.42133041 -0.77793715 -0.16233236]\n",
      " [ 1.57972247 -0.69032188  0.02990385]]\n",
      "\n",
      "h_t_prev\n",
      "\n",
      "[[ 0.66448566]\n",
      " [-1.23570622]]\n",
      "\n",
      "x_t\n",
      "\n",
      "[[0.44797211]\n",
      " [1.20045448]\n",
      " [0.37405119]]\n"
     ]
    }
   ],
   "source": [
    "print(\"w_hh\",w_hh,\"w_hx\",w_hx,\"h_t_prev\",h_t_prev,\"x_t\",x_t, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89efe5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7419451 ],\n",
       "       [ 0.0439067 ],\n",
       "       [ 1.09225621]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "     return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "bias = np.random.standard_normal((x_t.shape[0],1))\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408b7e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12807433]\n",
      " [0.15944535]\n",
      " [0.97830477]]\n"
     ]
    }
   ],
   "source": [
    "h_t = sigmoid(np.matmul(w_hh, h_t_prev) + np.matmul(w_hx, x_t) + bias)\n",
    "print(h_t)\n",
    "\n",
    "A = h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a25a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12807433]\n",
      " [0.15944535]\n",
      " [0.97830477]]\n"
     ]
    }
   ],
   "source": [
    "# Another way\n",
    "h_t = sigmoid(np.matmul(np.hstack((w_hh, w_hx)), np.vstack((h_t_prev, x_t))) + bias)\n",
    "print(h_t)\n",
    "\n",
    "B = h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda99baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e6eb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12807433],\n",
       "       [0.15944535],\n",
       "       [0.97830477]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way, too\n",
    "sigmoid(np.hstack((w_hh, w_hx)) @ np.vstack((h_t_prev, x_t)) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265212e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12807433],\n",
       "       [0.15944535],\n",
       "       [0.97830477]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way, too (this one is sexy)\n",
    "sigmoid(w_hh @ h_t_prev + w_hx @ x_t + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84a7f819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19276986, 0.22261268, 0.31235083],\n",
       "       [0.70758389, 0.65986792, 0.52531488],\n",
       "       [0.03087153, 0.09515606, 0.68606918]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.concatenate([h_t_prev, x_t])\n",
    "#w_hh.shape\n",
    "#sigmoid(np.dot(w_hh, np.concatenate([h_t_prev, x_t])) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d1dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.19 µs ± 242 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sigmoid(np.matmul(w_hh, h_t_prev) + np.matmul(w_hx, x_t) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ae8e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.9 µs ± 693 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sigmoid(np.matmul(np.hstack((w_hh, w_hx)), np.vstack((h_t_prev, x_t))) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652f81cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 µs ± 585 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sigmoid(np.hstack((w_hh, w_hx)) @ np.vstack((h_t_prev, x_t)) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "892e10a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.92 µs ± 465 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sigmoid(w_hh @ h_t_prev + w_hx @ x_t + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63509972",
   "metadata": {},
   "source": [
    "Lets use `@` for element-wise operations. It's easier to remember, shorter and faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407faff1",
   "metadata": {},
   "source": [
    "# Costs\n",
    "For one example costs can be calculated like this.\n",
    "\n",
    "<img src=\"img/rnn_costs_single.png\" align=\"left\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558f0ef",
   "metadata": {},
   "source": [
    "If several time steps *T* are involved, we're building average costs.\n",
    "\n",
    "<img src=\"img/rnn_costs_all.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61c075",
   "metadata": {},
   "source": [
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/KBmVE/cost-function-for-rnns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe2189",
   "metadata": {},
   "source": [
    "# Scan functions\n",
    "- Abstract RNNs for fast computation\n",
    "- Needed for GPU usage & parrallel computing\n",
    "\n",
    "![image.png](img/rnn_scan_functions.png)\n",
    "\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/rhso8/implementation-note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8b811",
   "metadata": {},
   "source": [
    "An evaluation metric used in this course is perplexity, which seems not to fit with [speech recognition tasks](https://www.researchgate.net/post/What-are-the-performance-measures-in-Speech-recognition) (?).\n",
    "\n",
    "Some more intuitive explanations towards perplexity:\n",
    "- https://towardsdatascience.com/evaluation-of-language-models-through-perplexity-and-shannon-visualization-method-9148fbe10bd0\n",
    "- https://www.cs.cmu.edu/~roni/papers/eval-metrics-bntuw-9802.pdf\n",
    "- https://www.quora.com/How-does-perplexity-function-in-natural-language-processing?share=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27171fb7",
   "metadata": {},
   "source": [
    "# Gated Recurrent Units (GRU)\n",
    "\n",
    "- In simple RNNs hidden state *h* gets updated from unit to unit\n",
    "- Problematic for long sequences (information loss each step -> vanishing gradients)\n",
    "- GRUs have additional formulas (gates) to compute to keep relevant information available through all states\n",
    "\n",
    "## Vanilla & GRU\n",
    "![simple_rnn_vs_gru.png](img/simple_rnn_vs_gru.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/t5L3H/gated-recurrent-units)\n",
    "\n",
    "The symbol $\\Gamma$ looking like a 'T' without its left 'arm' is called *gamma* (Greek). It is used for the equations of 'gates' taking care of updates ($\\Gamma_u$) & relevance ($\\Gamma_r$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a33f1c",
   "metadata": {},
   "source": [
    "# Testing simple RNNs & GRUs & Scan functions\n",
    "\n",
    "Following [this](https://www.coursera.org/learn/sequence-models-in-nlp/ungradedLab/jJn3o/vanilla-rnns-grus-and-the-scan-function) lab... Although, I'm wondering why we're calculating hidden states now in a different way than we did it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7f03767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "random.seed(10)                 \n",
    "\n",
    "emb = 128                       # Embedding size\n",
    "T = 256                         # Number of variables in the sequences\n",
    "h_dim = 16                      # Hidden state dimension\n",
    "h_0 = np.zeros((h_dim, 1))      # Initial hidden state\n",
    "\n",
    "w1 = random.standard_normal((h_dim, emb+h_dim))\n",
    "w2 = random.standard_normal((h_dim, emb+h_dim))\n",
    "w3 = random.standard_normal((h_dim, emb+h_dim))\n",
    "\n",
    "b1 = random.standard_normal((h_dim, 1))\n",
    "b2 = random.standard_normal((h_dim, 1))\n",
    "b3 = random.standard_normal((h_dim, 1))\n",
    "\n",
    "X = random.standard_normal((T, emb, 1))\n",
    "\n",
    "weights = [w1, w2, w3, b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c60efcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_V_RNN(inputs, weights):\n",
    "    x, h_t = inputs\n",
    "    wh, _, _, bh, _, _ = weights\n",
    "\n",
    "    # Returning new hidden state only\n",
    "    h_t = sigmoid(np.dot(wh, np.concatenate([h_t, x])) + bh)\n",
    "    \n",
    "    return h_t, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68043c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_GRU(inputs, weights): # Forward propagation for a single GRU cell\n",
    "    x, h_t = inputs\n",
    "    wu, wr, wc, bu, br, bc = weights\n",
    "\n",
    "    # Update gate\n",
    "    u = sigmoid(np.dot(wu, np.concatenate([h_t, x])) + bu)\n",
    "    \n",
    "    # Relevance gate\n",
    "    r = sigmoid(np.dot(wr, np.concatenate([h_t, x])) + br)\n",
    "\n",
    "    \n",
    "    # Candidate hidden state \n",
    "    c = np.dot(wc, np.concatenate([r * h_t, x])) + bc\n",
    "    c = np.tanh(c)\n",
    "    \n",
    "    # Returning new hidden state only\n",
    "    h_t = u * c + (1 - u) * h_t\n",
    "    \n",
    "    return h_t, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "434a2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(fn, elems, weights, h_0=None):\n",
    "    h_t = h_0\n",
    "    ys = []\n",
    "    \n",
    "    for x in elems:\n",
    "        y, h_t = fn([x, h_t], weights)\n",
    "        ys.append(y)\n",
    "    \n",
    "    return ys, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33326beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 ms ± 47.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit scan(forward_V_RNN, X, weights, h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c6289c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.41 ms ± 190 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit scan(forward_GRU, X, weights, h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3901f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
