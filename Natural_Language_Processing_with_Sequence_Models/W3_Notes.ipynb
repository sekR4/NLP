{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8975433",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "- in LSTM info goes through \n",
    "    - forget gate (gets prev. hidden state & $x^t1$), \n",
    "    - input gate (sigmoid, tanh), \n",
    "    - output gate (tanh)\n",
    "- LSTM can deal with long sequences (robust to vanishing gradients?)\n",
    "- https://www.youtube.com/watch?v=uSdku8Q3d0A\n",
    "\n",
    "## LSTM Math\n",
    "Some symbols look funny...ðŸ¤”\n",
    "![lstm_math.png](img/lstm_math.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/ANbcf/lstm-equations-optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2dfbe9",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "- scan text fast for desired info\n",
    "- find & extract defined entities (e.g. names, offensive vocab)\n",
    "\n",
    "## NER types\n",
    "- geographical (Germany)\n",
    "- organizations (EOS)\n",
    "- geopolitical (German)\n",
    "- time (June 2021)\n",
    "- artifacts (...)\n",
    "- persons (Angela Merkel)\n",
    "\n",
    "\n",
    "Labeled Sentence:\n",
    "*Sebastian (PER) fÃ¤hrt nÃ¤chste Woche (TIME) nach Erfurt (GEO).*\n",
    "\n",
    "## Examples Applied NER\n",
    "- efficient search engines (our confluence needs NER ðŸ˜)\n",
    "- recommendation engines (may not work for all recommendation use cases)\n",
    "- first level customer communication (call/chat) (e.g. forward customer to the best agent for his request)\n",
    "- tradobot (1. evaluate scraped content with NER, 2. trade accordingly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177ebbe",
   "metadata": {},
   "source": [
    "![acc.png](img/acc.png)\n",
    "[Source](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/odcLM/computing-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21849a9",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8747d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trax \n",
    "from trax import layers as tl\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from w3 import get_params, get_vocab\n",
    "import random as rnd\n",
    "\n",
    "# set random seeds to make this notebook easier to replicate (depricated)\n",
    "#trax.supervised.trainer_lib.init_random_number_generators(33)\n",
    "# https://github.com/google/trax/issues/920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6425952",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, tag_map = get_vocab('w3data/large/words.txt', 'w3data/large/tags.txt')\n",
    "t_sentences, t_labels, t_size = get_params(vocab, tag_map, 'w3data/large/train/sentences.txt', 'w3data/large/train/labels.txt')\n",
    "v_sentences, v_labels, v_size = get_params(vocab, tag_map, 'w3data/large/val/sentences.txt', 'w3data/large/val/labels.txt')\n",
    "test_sentences, test_labels, test_size = get_params(vocab, tag_map, 'w3data/large/test/sentences.txt', 'w3data/large/test/labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7ad55",
   "metadata": {},
   "source": [
    "### Looking at one training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd81fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 9, 15, 1, 16, 17, 18, 19, 20, 21]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(open('w3data/large/train/sentences.txt', 'r').readline(),\n",
    "      t_sentences[0],\n",
    "      t_labels[0], \n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2849b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-geo': 1, 'B-gpe': 2, 'B-per': 3, 'I-geo': 4, 'B-org': 5, 'I-org': 6, 'B-tim': 7, 'B-art': 8, 'I-art': 9, 'I-per': 10, 'I-gpe': 11, 'I-tim': 12, 'B-nat': 13, 'B-eve': 14, 'I-eve': 15, 'I-nat': 16}\n"
     ]
    }
   ],
   "source": [
    "print(tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a92d384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map[\"B-geo\"], tag_map[\"B-gpe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde359d",
   "metadata": {},
   "source": [
    "The `tag_map` contains various encoded tags. The example sentence above contains\n",
    "- one *geographical entity - geo* and \n",
    "- a *geopolitical entity - gpe*. \n",
    "\n",
    "Other abbreviations:\n",
    "* org: organization\n",
    "* per: person \n",
    "* tim: time indicator\n",
    "* art: artifact\n",
    "* eve: event\n",
    "* nat: natural phenomenon\n",
    "* O: filler word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b55db",
   "metadata": {},
   "source": [
    "Note, here we're differentiating between `B`-efore Tokens & `I`-nside Tokens:\n",
    "\n",
    "Examples:\n",
    "\n",
    "- *\\\"EOS (`B-org`) Solutions (`I-org`) is a great company.\\\"*\n",
    "\n",
    "- *\\\"We are Borg (`B-org`). Resistance is futile.\\\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35b41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size: int, x, y, pad: int, shuffle=False, verbose=False):\n",
    "    \"\"\"This generator creates batches of data to be feeded into the NN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "        integer describing the batch size\n",
    "        \n",
    "    x : List\n",
    "        list containing sentences where words are represented as integers\n",
    "        \n",
    "    y : List\n",
    "        list containing tags associated with the sentences\n",
    "        \n",
    "    pad : int\n",
    "        an integer representing a pad character\n",
    "        \n",
    "    shuffle : bool, optional\n",
    "        Shuffle the data order, by default False\n",
    "        \n",
    "    verbose : bool, optional\n",
    "        Print information during runtime, by default False\n",
    "\n",
    "    Yields\n",
    "    -------\n",
    "    Tuple (X,Y)\n",
    "        - X padded sentences, np.array(), shape = (batch_size, max_len)\n",
    "        - Y tags associated with the sentences in X , np.array(), shape = (batch_size, max_len)\n",
    "    \"\"\"\n",
    "\n",
    "    # count the number of lines in data_lines\n",
    "    num_lines = len(x)\n",
    "\n",
    "    # create an array with the indexes of data_lines that can be shuffled\n",
    "    lines_index = [*range(num_lines)]\n",
    "\n",
    "    # \"Everyday I'm shuffeling...\"\n",
    "    if shuffle:\n",
    "        rnd.shuffle(lines_index)\n",
    "\n",
    "    index = 0  # tracks current location in x, y\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Temporal arrays to store the raw x & y data for this batch\n",
    "        buffer_x,  buffer_y = [0] * batch_size, [0] * batch_size  \n",
    "        \n",
    "        max_len = 0 \n",
    "        for i in range(batch_size):\n",
    "            if index >= num_lines:\n",
    "                index = 0\n",
    "                if shuffle:\n",
    "                    rnd.shuffle(lines_index)\n",
    "\n",
    "            # Get current position & store the x value in buffer_x, buffer_y\n",
    "            buffer_x[i],buffer_y[i] = x[lines_index[index]],y[lines_index[index]]\n",
    "\n",
    "            # Get max len for later padding\n",
    "            lenx = len(buffer_x[i])\n",
    "            if lenx > max_len:\n",
    "                max_len = lenx  \n",
    "            index += 1\n",
    "\n",
    "        # create X,Y, NumPy arrays of size (batch_size, max_len) 'full' of pad value\n",
    "        X = np.full((batch_size, max_len), pad)\n",
    "        Y = np.full((batch_size, max_len), pad)\n",
    "\n",
    "        # copy values from lists to NumPy arrays. Use the buffered values\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            # Get the example (sentence as a tensor) & labels\n",
    "            # in buffer_x, buffer_y at the i index\n",
    "            x_i, y_i = buffer_x[i], buffer_y[i]\n",
    "\n",
    "            # Walk through each word in x_i\n",
    "            # & store word & label in x_i, y_i at position j into X,Y\n",
    "            for j in range(len(x_i)):   \n",
    "                X[i, j], Y[i, j] = x_i[j], y_i[j]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"index=\", index)\n",
    "        yield ((X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad677102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30) (5, 30) (5, 30) (5, 30)\n",
      "[    0     1     2     3     4     5     6     7     8     9    10    11\n",
      "    12    13    14     9    15     1    16    17    18    19    20    21\n",
      " 35180 35180 35180 35180 35180 35180] \n",
      " [    0     0     0     0     0     0     1     0     0     0     0     0\n",
      "     1     0     0     0     0     0     2     0     0     0     0     0\n",
      " 35180 35180 35180 35180 35180 35180]\n"
     ]
    }
   ],
   "source": [
    "# Testing the data generator\n",
    "batch_size = 5\n",
    "mini_sentences = t_sentences[0: 8]\n",
    "mini_labels = t_labels[0: 8]\n",
    "\n",
    "dg = data_generator(batch_size, \n",
    "                    mini_sentences, \n",
    "                    mini_labels, \n",
    "                    vocab[\"<PAD>\"], \n",
    "                    shuffle=False, \n",
    "                    verbose=False)\n",
    "X1, Y1 = next(dg)\n",
    "X2, Y2 = next(dg)\n",
    "\n",
    "print(Y1.shape, X1.shape, Y2.shape, X2.shape)\n",
    "print(X1[0][:], \"\\n\", Y1[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5d5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(vocab_size=35181, d_model=50, tags=tag_map):\n",
    "    '''\n",
    "      Input: \n",
    "        vocab_size - integer containing the size of the vocabulary\n",
    "        d_model - integer describing the embedding size\n",
    "      Output:\n",
    "        model - a trax serial model\n",
    "    '''\n",
    "    model = tl.Serial(\n",
    "      tl.Embedding(vocab_size=vocab_size, d_feature=d_model), # Embedding layer\n",
    "      tl.LSTM(50),                                            # LSTM layer\n",
    "      tl.Dense(len(tags)),                                    # Dense layer with len(tags) units\n",
    "      tl.LogSoftmax()                                         # LogSoftmax layer\n",
    "      )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a2389b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "rnd.seed(33)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create training data, mask pad id=35180 for training.\n",
    "train_generator = trax.data.inputs.add_loss_weights(\n",
    "    data_generator(batch_size, t_sentences, t_labels, vocab['<PAD>'], True),\n",
    "    id_to_mask=vocab['<PAD>'])\n",
    "\n",
    "# Create validation data, mask pad id=35180 for training.\n",
    "eval_generator = trax.data.inputs.add_loss_weights(\n",
    "    data_generator(batch_size, v_sentences, v_labels, vocab['<PAD>'], True),\n",
    "    id_to_mask=vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad2171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
